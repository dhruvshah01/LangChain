{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document(url):\n",
    "    loader = YoutubeLoader.from_youtube_url(url)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500, chunk_overlap = 100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_query(db, query):\n",
    "    docs = db.similarity_search(query, k = 4)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.7)\n",
    "\n",
    "    template = \"\"\"\n",
    "        You are a helpful assistant that that can answer questions about youtube videos \n",
    "        based on the video's transcript: {docs}\n",
    "        \n",
    "        Only use the factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    bot_prompt = SystemMessagePromptTemplate.from_template(template=template)\n",
    "\n",
    "    human_template = \"Answer the following question: {question}\"\n",
    "\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(template=human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [bot_prompt, human_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm = chat, prompt = chat_prompt)\n",
    "\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video is about the speaker's new workflow for\n",
      "data science projects using tools like chat GPT\n",
      "and GitHub co-pilot. They demonstrate their\n",
      "thought process and how they interact with these\n",
      "tools to complete a data science project\n",
      "efficiently. They also mention the importance of\n",
      "learning to use these AI tools effectively to stay\n",
      "relevant in the field. The video focuses on a\n",
      "specific data set from a Kaggle competition and\n",
      "the speaker's step-by-step approach to predict\n",
      "measurements in a manufacturing process.\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=th4j9JxWGko\"\n",
    "db = create_document(video_url)\n",
    "\n",
    "query = \"what is this video about?\"\n",
    "response, docs = get_response_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f255f50f561224cd89acd2611aa50c10498712376f1d5cc20297f375fa82cd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
